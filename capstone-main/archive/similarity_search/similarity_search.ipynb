{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain pinecone-client faiss-cpu -q\n",
    "%pip install langchain_community -q\n",
    "%pip install ipywidgets -q\n",
    "%pip install sentence-transformers -q\n",
    "%pip install langchain_pinecone -q\n",
    "%pip install langchain_openai -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone, FAISS\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "import pinecone\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_pinecone import PineconeEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_api_key(key):\n",
    "    path = \"/Users/khushalidaga/vs-code/capstone/openai_api.json\"\n",
    "    with open(path, \"r\") as file:\n",
    "        config = json.load(file)\n",
    "    return config[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word2vec():\n",
    "    path = \"/Users/khushalidaga/vs-code/capstone/metadata/bot_word2vec_representations.json\"\n",
    "    with open(path, 'r') as f:\n",
    "        agent_words = json.load(f)\n",
    "    return agent_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get agent words\n",
    "agent_words = get_word2vec()\n",
    "\n",
    "#  get pincone api key\n",
    "pinecone_key = load_api_key(\"PINECONE_API_KEY\")\n",
    "\n",
    "os.environ['PINECONE_API_KEY'] = pinecone_key\n",
    "\n",
    "# Initialize the embeddings model\n",
    "model_name = 'multilingual-e5-large'\n",
    "embeddings = PineconeEmbeddings(\n",
    "    model=model_name,\n",
    "    pinecone_api_key=pinecone_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index before upsert:\n",
      "{'dimension': 1024,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {},\n",
      " 'total_vector_count': 0}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Pinecone or FAISS vector database\n",
    "# For Pinecone:\n",
    "pc = Pinecone(api_key=pinecone_key)\n",
    "# Define the index settings\n",
    "index_name = \"vector-index\"\n",
    "dimension = 1024  # Dimension for 'all-MiniLM-L6-v2' embeddings model output\n",
    "\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=embeddings.dimension,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\"\n",
    "            ) \n",
    "    )\n",
    "    # Wait for index to be ready\n",
    "    while not pc.describe_index(index_name).status['ready']:\n",
    "        time.sleep(1)\n",
    "\n",
    "# Access the index\n",
    "vector_db = pc.Index(index_name)\n",
    "# See that it is empty\n",
    "print(\"Index before upsert:\")\n",
    "print(pc.Index(index_name).describe_index_stats())\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'bot_name': 'Customer Database Search'}, page_content='total, decisions, channels, average, metric, measuring, reveal, dividing, increase, brand, offers, purchases, calculate, behavioral, product'), Document(metadata={'bot_name': 'Organizational Information'}, page_content='hires, requesting, schedule, positive, providing, job, overview'), Document(metadata={'bot_name': 'Internet Search'}, page_content='growing, patients, analyze, consumers, adopt, commerce, working, reducing, latest, power, rise, environmentally, intelligence, presents, artificial')]\n"
     ]
    }
   ],
   "source": [
    "# Flatten the terms and scores into a format suitable for the Pinecone upsert\n",
    "documents = []\n",
    "for doc_name, word_weights in agent_words.items():\n",
    "    # Create a single string for each document by combining the word and its weight\n",
    "    doc = Document(\n",
    "        page_content=\", \".join(word_weights.keys()),  # Text could be a concatenation of words\n",
    "        metadata={\"bot_name\": doc_name}  # Add any other relevant metadata if needed\n",
    "    )\n",
    "    documents.append(doc)\n",
    "\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index after upsert:\n",
      "{'dimension': 1024,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'wondervector5000': {'vector_count': 9}},\n",
      " 'total_vector_count': 9}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "namespace = \"wondervector5000\"\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=documents,\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings,\n",
    "    namespace=namespace\n",
    ")\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "# See how many vectors have been upserted\n",
    "print(\"Index after upsert:\")\n",
    "print(pc.Index(index_name).describe_index_stats())\n",
    "print(\"\\n\")\n",
    "time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Can you provide a list of customers who've been featured in our marketing materials?\n",
      "\n",
      "Results:\n",
      "Bot: Customer Database Search\n",
      "Similarity Score: 0.813858\n",
      "Content: total, decisions, channels, average, metric, measu...\n",
      "\n",
      "Bot: Customer Database Search\n",
      "Similarity Score: 0.812541604\n",
      "Content: total decisions channels average metric measuring ...\n",
      "\n",
      "Bot: Organizational Information\n",
      "Similarity Score: 0.808923662\n",
      "Content: hires, requesting, schedule, positive, providing, ...\n",
      "\n",
      "Bot: Internet Search\n",
      "Similarity Score: 0.808375895\n",
      "Content: growing, patients, analyze, consumers, adopt, comm...\n",
      "\n",
      "Bot: Internet Search\n",
      "Similarity Score: 0.80659622\n",
      "Content: growing patients analyze consumers adopt commerce ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform similarity search with scores\n",
    "query = \"Can you provide a list of customers who've been featured in our marketing materials?\"\n",
    "results = docsearch.similarity_search_with_score(query, k=5)\n",
    "\n",
    "# Print results\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(\"Results:\")\n",
    "for doc, score in results:\n",
    "    print(f\"Bot: {doc.metadata['bot_name']}\")\n",
    "    print(f\"Similarity Score: {score}\")\n",
    "    print(f\"Content: {doc.page_content[:50]}...\")  # Truncate content for readability\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Scores for each bot:\n",
      "Customer Database Search: 0.813200\n",
      "Organizational Information: 0.808924\n",
      "Internet Search: 0.807486\n",
      "\n",
      "Most relevant bot: Customer Database Search\n",
      "Highest average score: 0.813200\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average similarity score for each bot\n",
    "score_dict = {}\n",
    "for doc, score in results:\n",
    "    bot = doc.metadata['bot_name']\n",
    "    if bot not in score_dict:\n",
    "        score_dict[bot] = {'total_score': 0, 'count': 0}\n",
    "    score_dict[bot]['total_score'] += score\n",
    "    score_dict[bot]['count'] += 1\n",
    "\n",
    "# Calculate averages\n",
    "average_scores = {bot: data['total_score'] / data['count'] for bot, data in score_dict.items()}\n",
    "\n",
    "# Find the bot with the highest average score\n",
    "best_bot = max(average_scores, key=average_scores.get)\n",
    "best_score = average_scores[best_bot]\n",
    "\n",
    "# Print results\n",
    "print(\"Average Scores for each bot:\")\n",
    "for bot, score in average_scores.items():\n",
    "    print(f\"{bot}: {score:.6f}\")\n",
    "\n",
    "print(f\"\\nMost relevant bot: {best_bot}\")\n",
    "print(f\"Highest average score: {best_score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
